{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selectorlib import Extractor\n",
    "import requests \n",
    "import json \n",
    "from time import sleep\n",
    "import csv\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "# Create an Extractor by reading from the YAML file\n",
    "e = Extractor.from_yaml_file('selectors.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):    \n",
    "    headers = {\n",
    "        'authority': 'www.amazon.com',\n",
    "        'pragma': 'no-cache',\n",
    "        'cache-control': 'no-cache',\n",
    "        'dnt': '1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'sec-fetch-site': 'none',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    }\n",
    "\n",
    "    # Download the page using requests\n",
    "    #print(\"Downloading %s\"%url)\n",
    "    r = requests.get(url, headers=headers)\n",
    "    # Simple check to check if page was blocked (Usually 503)\n",
    "    if r.status_code > 500:\n",
    "        if \"To discuss automated access to Amazon data please contact\" in r.text:\n",
    "            print(\"Page %s was blocked by Amazon. Please try using better proxies\\n\"%url)\n",
    "        else:\n",
    "            print(\"Page %s must have been blocked by Amazon as the status code was %d\"%(url,r.status_code))\n",
    "        return None\n",
    "    # Pass the HTML of the page and create \n",
    "    return e.extract(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def packing(data): \n",
    "    if data:\n",
    "        for r in data['reviews']:\n",
    "            r[\"product\"] = data[\"product_title\"]\n",
    "            r['url'] = url\n",
    "            if 'verified' in r and r['verified'] is not None:\n",
    "                if 'Verified Purchase' in r['verified']:\n",
    "                    r['verified'] = 'Yes'\n",
    "                else:\n",
    "                    r['verified'] = 'Yes'\n",
    "            else: \n",
    "                    r['verified'] = \"No\"\n",
    "            r['rating'] = r['rating'].split(' out of')[0]\n",
    "            date_posted = r['date'].split('on ')[-1]\n",
    "            if r['images']:\n",
    "                r['images'] = \"\\n\".join(r['images'])\n",
    "            r['date'] = dateparser.parse(date_posted).strftime('%d %b %Y')\n",
    "            writer.writerow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=44\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=43\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=42\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=41\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=40\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=39\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=38\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=37\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=36\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=35\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=34\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=33\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=32\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=31\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=30\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=29\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=28\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=27\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=26\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=25\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=24\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=23\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=22\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=21\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=20\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=19\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=18\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=17\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=16\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=15\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=14\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=13\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=12\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=11\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.com/Thick-It-RD26929208-36-OZ/product-reviews/B0011TUM3E/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=13\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=12\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=11\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.com/Thick-Instant-Beverage-Thickener-Original/product-reviews/B00FBP39PC/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.com/Original-Thick-Food-Thickener-Ounce/product-reviews/B003MT0Q4Q/ref=cm_cr_getr_d_paging_btm_next_3?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.com/Original-Thick-Food-Thickener-Ounce/product-reviews/B003MT0Q4Q/ref=cm_cr_getr_d_paging_btm_next_3?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.com/Original-Thick-Food-Thickener-Ounce/product-reviews/B003MT0Q4Q/ref=cm_cr_getr_d_paging_btm_next_3?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.com/Original-Thick-Food-Thickener-Ounce/product-reviews/B003MT0Q4Q/ref=cm_cr_getr_d_paging_btm_next_3?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.com/Original-Thick-Food-Thickener-Ounce/product-reviews/B003MT0Q4Q/ref=cm_cr_getr_d_paging_btm_next_3?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.com/Thick-It-Original-Thickener-10-Ounce/product-reviews/B00CMQDPC0/ref=cm_cr_arp_d_paging_btm_next_7?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
      "https://www.amazon.com/Thick-MIIJ585-Instant-Beverage-Thickener/product-reviews/B002NH9KCM/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9d5650449fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-8ade65ec6a7c>\u001b[0m in \u001b[0;36mpacking\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"No\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' out of'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mdate_posted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "with open('urls.txt', 'r') as urls:\n",
    "    for url in urls.readlines():\n",
    "        lastPage = int(url.split('=')[-1]) #extract last page number\n",
    "        url = url[0:-1]\n",
    "        for x in range(lastPage, 0, -1):\n",
    "            print(url)\n",
    "            pages.append(url)\n",
    "            url = url.replace(\"pageNumber=\" + str(x), \"pageNumber=\" + str(x-1))\n",
    "with open('data.csv','a') as outfile, open('urls.txt', 'r') as preurllist:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=[\"title\",\"content\",\"date\",\"variant\",\"images\",\"verified\",\"author\",\"rating\",\"product\",\"url\"],quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for url in pages: \n",
    "        data = scrape(url)\n",
    "        packing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('urls.txt', 'r') as preurllist:\n",
    "    ID = 0\n",
    "    for url in preurllist.readlines():\n",
    "        lastPage = int(url.split('=')[-1]) #extract last page number\n",
    "        for x in range(lastPage, 0, -1):\n",
    "            name =  \"URLS/\" + str(ID) + \".txt\"\n",
    "            with open(name, 'w') as prourllist:\n",
    "                prourllist.write(url)\n",
    "                url = url.replace(\"pageNumber=\" + str(x), \"pageNumber=\" + str(x-1))\n",
    "                ID += 1\n",
    "                prourllist.close()\n",
    "    preurllist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-61ac6774aa82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m77\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'URLS/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0murlfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mpacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0murlfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8ade65ec6a7c>\u001b[0m in \u001b[0;36mpacking\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"No\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' out of'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mdate_posted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "with open('data.csv','w') as outfile: \n",
    "    outfile.close()\n",
    "with open('data.csv','a') as outfile: \n",
    "    writer = csv.DictWriter(outfile, fieldnames=[\"title\",\"content\",\"date\",\"variant\",\"images\",\"verified\",\"author\",\"rating\",\"product\",\"url\"],quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for x in range(0, 77):\n",
    "        with open('URLS/'+ str(x) + '.txt') as urlfile:\n",
    "            packing(scrape(urlfile.read()[0:-1]))\n",
    "            urlfile.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('data.csv','w') as outfile: \n",
    "    outfile.close()\n",
    "with open('data.csv','a') as outfile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_data = []\n",
    "with open('data.csv','w') as outfile: \n",
    "    outfile.close()\n",
    "with open('data.csv','a') as outfile, open('urls.txt', 'r') as preurllist:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=[\"title\",\"content\",\"date\",\"variant\",\"images\",\"verified\",\"author\",\"rating\",\"product\",\"url\"],quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for url in preurllist.readlines():\n",
    "        lastPage = int(url.split('=')[-1]) #extract last page number\n",
    "        temp = url \n",
    "        for x in range(lastPage, 0, -1):\n",
    "            \n",
    "            with open('processedurl.txt', 'w') as prourl:\n",
    "                prourl.write(url)\n",
    "                prourl.close()\n",
    "            with open('processedurl.txt', 'r') as prourl:\n",
    "                url = prourl.read() \n",
    "                print(url)\n",
    "                data = scrape(url)\n",
    "                packing(data)\n",
    "                prourl.close()\n",
    "            url = url.replace(\"pageNumber=\" + str(x), \"pageNumber=\" + str(x-1))\n",
    "            \n",
    "    preurllist.close()\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_data = []\n",
    "with open('data.csv','w') as outfile: \n",
    "    outfile.close()\n",
    "with open(\"URLS/0.txt\",'r') as urllist, open('data.csv','a') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=[\"title\",\"content\",\"date\",\"variant\",\"images\",\"verified\",\"author\",\"rating\",\"product\",\"url\"],quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for url in urllist.readlines():\n",
    "        lastPage = int(url.split('=')[-1]) #extract last page number\n",
    "        temp = url\n",
    "        for x in range(lastPage, 0, -1):\n",
    "        data = scrape(temp)\n",
    "        if data:\n",
    "            for r in data['reviews']:\n",
    "                r[\"product\"] = data[\"product_title\"]\n",
    "                r['url'] = url\n",
    "                if 'verified' in r and r['verified'] is not None:\n",
    "                    if 'Verified Purchase' in r['verified']:\n",
    "                        r['verified'] = 'Yes'\n",
    "                    else:\n",
    "                        r['verified'] = 'Yes'\n",
    "                else: \n",
    "                        r['verified'] = \"No\"\n",
    "                r['rating'] = r['rating'].split(' out of')[0]\n",
    "                date_posted = r['date'].split('on ')[-1]\n",
    "                if r['images']:\n",
    "                    r['images'] = \"\\n\".join(r['images'])\n",
    "                r['date'] = dateparser.parse(date_posted).strftime('%d %b %Y')\n",
    "                writer.writerow(r)\n",
    "            temp = temp.replace(\"pageNumber=\" + str(x), \"pageNumber=\" + str(x-1))\n",
    "            print(temp)\n",
    "            #    sleep(5)\n",
    "\"\"\"\"\"\"\n",
    "with open(\"URLS/1.txt\",'r') as urllist, open('data.csv','a') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=[\"title\",\"content\",\"date\",\"variant\",\"images\",\"verified\",\"author\",\"rating\",\"product\",\"url\"],quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for url in urllist.readlines():\n",
    "        #lastPage = int(url.split('=')[-1]) #extract last page number\n",
    "        #for x in range(lastPage, 0, -1):\n",
    "        data = scrape(url)\n",
    "        if data:\n",
    "            for r in data['reviews']:\n",
    "                r[\"product\"] = data[\"product_title\"]\n",
    "                r['url'] = url\n",
    "                if 'verified' in r and r['verified'] is not None:\n",
    "                    if 'Verified Purchase' in r['verified']:\n",
    "                        r['verified'] = 'Yes'\n",
    "                    else:\n",
    "                        r['verified'] = 'Yes'\n",
    "                else: \n",
    "                        r['verified'] = \"No\"\n",
    "                r['rating'] = r['rating'].split(' out of')[0]\n",
    "                date_posted = r['date'].split('on ')[-1]\n",
    "                if r['images']:\n",
    "                    r['images'] = \"\\n\".join(r['images'])\n",
    "                r['date'] = dateparser.parse(date_posted).strftime('%d %b %Y')\n",
    "                writer.writerow(r)\n",
    "            #url = url.replace(\"pageNumber=\" + str(x), \"pageNumber=\" + str(x-1))\n",
    "            #print(url)\n",
    "                sleep(5)\n",
    "with open(\"URLS/2.txt\",'r') as urllist, open('data.csv','a') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=[\"title\",\"content\",\"date\",\"variant\",\"images\",\"verified\",\"author\",\"rating\",\"product\",\"url\"],quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for url in urllist.readlines():\n",
    "        #lastPage = int(url.split('=')[-1]) #extract last page number\n",
    "        #for x in range(lastPage, 0, -1):\n",
    "        data = scrape(url)\n",
    "        if data:\n",
    "            for r in data['reviews']:\n",
    "                r[\"product\"] = data[\"product_title\"]\n",
    "                r['url'] = url\n",
    "                if 'verified' in r and r['verified'] is not None:\n",
    "                    if 'Verified Purchase' in r['verified']:\n",
    "                        r['verified'] = 'Yes'\n",
    "                    else:\n",
    "                        r['verified'] = 'Yes'\n",
    "                else: \n",
    "                        r['verified'] = \"No\"\n",
    "                r['rating'] = r['rating'].split(' out of')[0]\n",
    "                date_posted = r['date'].split('on ')[-1]\n",
    "                if r['images']:\n",
    "                    r['images'] = \"\\n\".join(r['images'])\n",
    "                r['date'] = dateparser.parse(date_posted).strftime('%d %b %Y')\n",
    "                writer.writerow(r)\n",
    "            #url = url.replace(\"pageNumber=\" + str(x), \"pageNumber=\" + str(x-1))\n",
    "            #print(url)\n",
    "                sleep(5)\n",
    "                \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from: https://github.com/scrapehero-code/amazon-review-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
